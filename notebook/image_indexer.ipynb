{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf88110",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "data_folder_path = \"/mnt/mmlab2024nas/anhndt/Batch1/frames/Videos_L21_a\"\n",
    "sys.path.append(data_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0293a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Union, List\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "def collect_jpg_paths(folder_path: Union[Path, str], max_workers: int = 8) -> List[str]:\n",
    "    \"\"\"\n",
    "    Scan the given folder and return a list of all .jpg file paths found \n",
    "    in its subfolders using multithreading for faster I/O operations.\n",
    "\n",
    "    Args:\n",
    "        folder_path: Root folder to scan (can be Path or string)\n",
    "        max_workers: Number of threads to use for scanning\n",
    "\n",
    "    Returns:\n",
    "        List of file paths to all .jpg images in the folder and its subfolders\n",
    "    \"\"\"\n",
    "    # Ensure folder_path is a Path object\n",
    "    if isinstance(folder_path, str):\n",
    "        folder_path = Path(folder_path)\n",
    "\n",
    "    # Get first-level subdirectories only\n",
    "    subfolders = [p for p in folder_path.iterdir() if p.is_dir()]\n",
    "\n",
    "    # List to collect all jpg file paths\n",
    "    jpg_files = []\n",
    "\n",
    "    def scan_folder(subfolder: Path) -> List[str]:\n",
    "        \"\"\"Scan all .jpg files recursively in a single subfolder.\"\"\"\n",
    "        return [str(p) for p in subfolder.rglob(\"*.jpg\")]\n",
    "\n",
    "    # Use ThreadPoolExecutor to scan multiple subfolders concurrently\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit tasks for each subfolder\n",
    "        futures = [executor.submit(scan_folder, subfolder)\n",
    "                   for subfolder in subfolders]\n",
    "\n",
    "        # Collect results as tasks complete\n",
    "        for future in as_completed(futures):\n",
    "            jpg_files.extend(future.result())\n",
    "\n",
    "    return jpg_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "837da0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31945"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpg_list = collect_jpg_paths(data_folder_path, max_workers=8)\n",
    "len(jpg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a7dac0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/mmlab2024nas/anhndt/Batch1/frames/Videos_L21_a/L21_V007/L21_V007_00031.jpg'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpg_path = jpg_list[0]\n",
    "jpg_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60c2a4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L23_a V001 00026\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "path = \"/mnt/mmlab2024nas/anhndt/Batch1/frames/Videos_L23_a/L23_V001/L23_V001_00026.jpg\"\n",
    "\n",
    "# Regex pattern:\n",
    "# 1. Lấy L23_a sau 'Videos_'\n",
    "# 2. Lấy V001 trong tên folder/video\n",
    "# 3. Lấy 00026 trước .jpg\n",
    "pattern = r\"Videos_(L\\d+_[a-z])/.+?/(L\\d+_(V\\d+)_(\\d+))\\.jpg\"\n",
    "\n",
    "match = re.search(pattern, path)\n",
    "\n",
    "if match:\n",
    "    video_folder = match.group(1)  # L23_a\n",
    "    video_id = match.group(3)      # V001\n",
    "    frame_id = match.group(4)      # 00026\n",
    "    print(video_folder, video_id, frame_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55eccca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_path_info(example: str):\n",
    "    \"\"\"\n",
    "    Parse video path to extract:\n",
    "    - video_folder (e.g., L23_a)\n",
    "    - video_id (e.g., V001)\n",
    "    - frame_id (e.g., 00026)\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: if the path does not match the expected pattern\n",
    "    \"\"\"\n",
    "    pattern = r\"Videos_(L\\d+_[a-z])/.+?/(L\\d+_(V\\d+)_(\\d+))\\.jpg\"\n",
    "    match = re.search(pattern, example)\n",
    "\n",
    "    if match:\n",
    "        video_folder = match.group(1)  # L23_a\n",
    "        video_id = match.group(3)      # V001\n",
    "        frame_id = match.group(4)      # 00026\n",
    "        return video_folder, video_id, frame_id\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid path format: {example}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea8a4cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing path info...: 100%|██████████| 340323/340323 [00:00<00:00, 572045.67it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "frames_info = []\n",
    "for jpg_path in tqdm(jpg_list, desc=\"Parsing path info...\"):\n",
    "    video_folder, video_id, frame_id = parse_path_info(jpg_path)\n",
    "    frame_info = {\n",
    "        \"video_folder\": video_folder,\n",
    "        \"video_id\": video_id,\n",
    "        \"frame_id\": frame_id,\n",
    "        \"path\": jpg_path\n",
    "    }\n",
    "    frames_info.append(frame_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cb0c0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video_folder': 'L23_a',\n",
       " 'video_id': 'V001',\n",
       " 'frame_id': '00026',\n",
       " 'path': '/mnt/mmlab2024nas/anhndt/Batch1/frames/Videos_L23_a/L23_V001/L23_V001_00026.jpg'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_info[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0c5aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Union, List\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_path_info(example: str):\n",
    "    \"\"\"\n",
    "    Parse a single .jpg file path to extract metadata.\n",
    "\n",
    "    Example input:\n",
    "        /mnt/.../Videos_L23_a/L23_V001/L23_V001_00026.jpg\n",
    "\n",
    "    Returns:\n",
    "        dict with keys:\n",
    "            - video_folder: e.g., \"L23_a\"\n",
    "            - video_id: e.g., \"V001\"\n",
    "            - frame_id: e.g., \"00026\"\n",
    "            - path: the original file path\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if the path does not match the expected format.\n",
    "    \"\"\"\n",
    "    # Regex pattern to extract video folder, video id, and frame id\n",
    "    pattern = r\"Videos_(L\\d+_[a-z])/.+?/(L\\d+_(V\\d+)_(\\d+))\\.jpg\"\n",
    "    match = re.search(pattern, example)\n",
    "\n",
    "    if match:\n",
    "        # Extract and return metadata as a dictionary\n",
    "        video_folder = match.group(1)  # Example: L23_a\n",
    "        video_id = match.group(3)      # Example: V001\n",
    "        frame_id = match.group(4)      # Example: 00026\n",
    "        return {\n",
    "            \"video_folder\": video_folder,\n",
    "            \"video_id\": video_id,\n",
    "            \"frame_id\": frame_id,\n",
    "            \"path\": example\n",
    "        }\n",
    "    else:\n",
    "        # Raise an error if the path format is unexpected\n",
    "        raise ValueError(f\"Invalid path format: {example}\")\n",
    "\n",
    "\n",
    "def parse_frames_info(folder_path: Union[Path, str], max_workers: int = 16) -> List[dict]:\n",
    "    \"\"\"\n",
    "    Recursively scan a folder for .jpg files and parse each into metadata using multithreading.\n",
    "\n",
    "    Args:\n",
    "        folder_path: Root folder containing video frame subfolders (Path or string).\n",
    "        max_workers: Number of threads to use for concurrent scanning.\n",
    "\n",
    "    Returns:\n",
    "        List of dictionaries, each containing:\n",
    "            {\n",
    "                \"video_folder\": str,\n",
    "                \"video_id\": str,\n",
    "                \"frame_id\": str,\n",
    "                \"path\": str\n",
    "            }\n",
    "    \"\"\"\n",
    "    # Convert folder_path to Path object if needed\n",
    "    if isinstance(folder_path, str):\n",
    "        folder_path = Path(folder_path)\n",
    "\n",
    "    # Get first-level subdirectories to parallelize scanning\n",
    "    subfolders = [p for p in folder_path.iterdir() if p.is_dir()]\n",
    "\n",
    "    # Container to store all parsed frame metadata\n",
    "    frames_info = []\n",
    "\n",
    "    def scan_folder(subfolder: Path) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Recursively scan a single subfolder for .jpg files\n",
    "        and parse each path into a metadata dictionary.\n",
    "        \"\"\"\n",
    "        return [parse_path_info(str(p)) for p in subfolder.rglob(\"*.jpg\")]\n",
    "\n",
    "    # Use ThreadPoolExecutor to scan subfolders concurrently\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit a scan task for each subfolder\n",
    "        futures = [executor.submit(scan_folder, subfolder) for subfolder in subfolders]\n",
    "\n",
    "        # Collect results as tasks complete\n",
    "        for future in as_completed(futures):\n",
    "            frames_info.extend(future.result())\n",
    "\n",
    "    return frames_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83a9ef97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 340323 frame infos to frames_info.txt\n"
     ]
    }
   ],
   "source": [
    "frames_info = parse_frames_info(data_folder_path, max_workers=8)\n",
    "\n",
    "output_file = \"frames_info.txt\"\n",
    "\n",
    "# Write each frame_info tuple as a line\n",
    "with open(output_file, \"w\") as f:\n",
    "    for info in frames_info:\n",
    "        f.write(f\"{info}\\n\")\n",
    "\n",
    "print(f\"Saved {len(frames_info)} frame infos to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1759c9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 340323 frames info to frames_info.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "frames_info = parse_frames_info(data_folder_path, max_workers=8)\n",
    "\n",
    "output_file = \"frames_info.json\"\n",
    "\n",
    "# Save list[dict] to a JSON file with pretty formatting\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(frames_info, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(frames_info)} frames info to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd00065b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aic2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
